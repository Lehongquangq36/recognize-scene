# -*- coding: utf-8 -*-
"""Scene Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LuvMZ5xoTFI0PJV36KVH5lF-pR4a9Iqp
"""

# from google.colab import drive
# drive.mount('/content/drive')

import os
import numpy as np
import tensorflow
import keras
import cv2, random
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation
from keras.optimizers import RMSprop
from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping
from keras.utils import np_utils, to_categorical
from keras.datasets import mnist
print("tensorflow version: ", tensorflow.__version__)
print("keras version: ", keras.__version__)

# os.listdir('drive/My Drive/Scene Classification')

# !unzip -q 'drive/My Drive/Scene Classification/data.zip' -d scene

# link data
city_path = './data/city'
forest_path = './data/forest'
sea_path = './data/sea'

# format image
HEIGHT = 256
WIDTH = 256
DEEP = 3 # nó biểu thị cho màu RGB

# link image
city_image_path = [os.path.join(city_path,i) for i in os.listdir(city_path)]
forest_image_path = [os.path.join(forest_path,i) for i in os.listdir(forest_path)]
sea_image_path = [os.path.join(sea_path,i) for i in os.listdir(sea_path)]

# init label city:0, forest:1, sea:2
city_label = [0 for i in range(len(city_image_path))]
forest_label = [1 for i in range(len(forest_image_path))]
sea_label = [2 for i in range(len(sea_image_path))]

print(len(city_image_path), len(forest_image_path), len(sea_image_path))

#path and label for training 

train_image_path = city_image_path[:480] + forest_image_path[:480] + sea_image_path[:480]   # total image 0 -> 480
train_label = city_label[:480] + forest_label[:480] + sea_label[:480]                       # total label

#path and label for test

test_image_path = city_image_path[480:] + forest_image_path[480:] + sea_image_path[480:]    # data test 480 -> hết

print(len(train_image_path), len(train_label), len(test_image_path))

# Shuffle data (Tron du lieu)
# list() convert and return a list
# zip(iterator1, iterator2, ...) ghép các phần tử Ex: 
# a = ("John", "Charles", "Mike")
# b = ("Jenny", "Christy", "Monica") 
# x = zip(a, b) => x: (('John', 'Jenny'), ('Charles', 'Christy'), ('Mike', 'Monica'))

z = list(zip(train_image_path, train_label)) 
# Trộn dữ liệu trong z
random.shuffle(z)
# unzip lấy lại dữ liệu train_image_path, train_label
train_image_path, train_label  = zip(*z)

# function đọc, convert ảnh theo 1 quy chuẩn
def read_image(image_path):
  # đọc ảnh ( giá trị trả về chính là ảnh đó), nếu muốn giá trị trả về là ảnh xám thì cv2.imread(path, 0)
  image = cv2.imread(image_path)
  # Chuyển đổi hình ảnh sang 1 không gian màu khác.
  image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
  # interpolation: phép nội suy: NEAREST, LINEAR, AREA, CUBIC: nội suy hai chiều trên vùng lân cận 4 × 4 pixel, LANCZOS4
  return cv2.resize(image,(HEIGHT,WIDTH),interpolation = cv2.INTER_CUBIC)

# function trả về 1 danh sách ảnh đã theo 1 quy chuẩn từ đường dẫn vào.
def load_data(list_path):
  image_list= []
  for i, image_path in enumerate(list_path):
    image = read_image(image_path)
    image_list.append(image)
    if i % 500 == 0 : print('load {} in {} images'.format(i,len(list_path)))
  return image_list

one_hot_labels = np.zeros((len(train_label),3))
for i in range(len(train_label)) :
  one_hot_labels[i][train_label[i]] = 1
train_labels_1hot = one_hot_labels
train_labels_1hot.shape

# load data  
print("Loading data .................")
train_image = load_data(train_image_path)
test_image = load_data(test_image_path)

label_name = ['city', 'forest', 'sea']
# demo data
print("Demo 5 image ...............")
for i in range(5) :
  print("{}".format(label_name[train_label[i]]))
  plt.imshow(train_image[i])
  plt.show()
print("End demo 5 image .......................")
train_image = np.array(train_image)
train_label = np.array(train_label)
train_label = np.reshape(train_label,(-1,1))

"""#Build Model"""

objective = 'categorical_crossentropy'
adam = keras.optimizers.Adam(lr=0.0001) # thuật toán training thông qua tham số  

# CNN là một kiến trúc mạng neuron rất thích hợp cho các bài toán mà dữ liệu là ảnh hoặc video. 
# Có 2 loại layer chính trong CNN: convolutional layer lớp chập (Conv1D, Conv2D) 
#                                   và pooling layer lớp tổng hợp ().

# kích thước ảnh đầu ra :--------------------------
# padding = same : tạo đệm padding = 0, ouput_shape = input_shape / strides and = input_shape if strides = 1, valid : ko tạo thêm phần đệm
#Conv1D, Conv2D mạng neuron tích chập lấy đặc điểm từ image, lớp đầu tiên phải cung cấp input_shape
# kernel_size : kích thước window search trên ảnh
# Conv2D: 32 - số lượng neuron hay kích thước không gian đầu ra (số lượng bộ lọc trong tích chập)
#         kernel size : kích cỡ của cửa sổ tích chập ex: image: (x,y), audio: (x,y,z) 
#         activation: tham số dùng để kích hoạt chọn activation trong layer
# MaxPooloing2D: dùng để lấy feature nổi bật(dùng max) và giúp giảm parameter khi training 

def catdog():
    model = Sequential() # Khởi tạo 1 model trong keras, add - method 
    model.add(Conv2D(32,kernel_size=(3,3), strides = 1,padding ='same',input_shape=(HEIGHT,WIDTH,DEEP),activation='relu'))
    model.add(Conv2D(32,kernel_size=(3,3), strides = 1,padding ='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2))) 

    model.add(Conv2D(64, kernel_size=(3,3), strides = 1, padding = 'same', activation='relu'))
    model.add(Conv2D(64, kernel_size=(3,3), strides = 1, padding = 'same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Conv2D(128, kernel_size=(3,3), strides = 1,padding='same', activation='relu'))
    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, padding='same', activation='relu'))
#     model.add(Convolution2D(128, 3, 3, padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Conv2D(256, kernel_size=(3,3), strides = 1, padding='same', activation='relu'))
    model.add(Conv2D(256, kernel_size=(3,3), strides = 1, padding='same', activation='relu'))
#     model.add(Convolution2D(256, 3, 3, padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Conv2D(256, kernel_size=(3,3), strides = 1, padding='same', activation='relu'))
    model.add(Conv2D(256, kernel_size=(3,3), strides = 1, padding='same', activation='relu'))
#     model.add(Convolution2D(256, 3, 3, padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    # Flatten dùng để lát phằng layer (convert thành mảng 1 chiều), vd : shape : 20x20 qua layer này sẽ là 400x1
    model.add(Flatten())

    # Dense là 1 lớp neurol net work bình thường (đầu vào phải có rank = 1, tức mảng 1 chiều)
    # 256 - số chiều không gian đầu ra = số neurol , nếu ko có activation thì kích hoạt tuyến tính : a(x) = x
    model.add(Dense(256, activation='relu'))
    
    # Làm giảm overfitting (chống học quá vừa vặn)
    # kỹ thuật dropout là việc chúng ta sẽ bỏ qua một vài unit trong suốt quá trình train trong mô hình, 
    # những unit bị bỏ qua được lựa chọn ngẫu nhiên. 
    # Ở đây, chúng ta hiểu “bỏ qua - ignoring” là unit đó sẽ không tham gia 
    # và đóng góp vào quá trình huấn luyện (lan truyền tiến và lan truyền ngược).
    #Về mặt kỹ thuật, tại mỗi giai đoạn huấn luyện, 
    # mỗi node có xác suất bị bỏ qua là 1-p và xác suất được chọn là p

    model.add(Dropout(0.5))
    
    model.add(Dense(256, activation='relu'))
    model.add(Dropout(0.5))

    model.add(Dense(3))

    # activation softmax dùng trong đa phân loại tổng hợp tất cả.
    model.add(Activation('softmax'))
    # Biên tập lại toàn bộ model :
    # optimizer: thuật toán training, function loss, metrics : hiển thị khi model được training
    # loss function: hiệu năng của model trong quá trình trainning và học, opitmizer điều chỉnh 
    # việc cập nhật các trọng số trong mạng noron.
    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics=['accuracy'])
    return model
# Create instance of Model
VGG13 = catdog()
# summary: method giúp chúng ta tổng hợp model có bao nhiêu layer, tổng số tham số và shape của mỗi layer.
VGG13.summary()

"""#Tranning
+ Train_image
+ Train_label
"""

print(train_image.shape, train_label.shape, train_labels_1hot.shape)
# Start trainning:
# fit() ???????????????????????????????-------------------------------------------------------------
print("Start tranining:...............")
VGG13.fit(train_image,train_labels_1hot, batch_size=16,  epochs= 6, validation_split=0.1, shuffle=True)

# Lưu kết quả training vào file trained_model.h5: ma trận trọng số.
print("Create and Write result to file trained_model.hdf5")
VGG13.save('trained_model.hdf5')

# Lấy dữ liệu đã train lên để test
print("Lấy ma trận weights từ file tranined_model...hdf5 ")
VGG13.load_weights('trained_model_1v.hdf5')
"""#Test"""

def test(index):
  # predict() sử dụng mô hình để dự đoán ảnh đầu vào.
  # predict() hoạt động ntn ???????????????????======================================================
  # Kết quả thu được là 1 vector được flatted [...[..]....[..]...]
  predict = VGG13.predict(test_image[index].reshape((1,HEIGHT,WIDTH,DEEP)))
  plt.imshow(test_image[index])
  plt.show()
  # np.argmax(a) will give index of max value in flatted array of given matrix
  if np.argmax(predict) == 0: 
    print('I am sure this is city')
  elif np.argmax(predict) == 1:
    print('I am sure this is forest')
  else:      
    print('I am sure this is sea')

test(1)

